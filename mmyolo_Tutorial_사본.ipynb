{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davJ-star/CV_yolo/blob/main/mmyolo_Tutorial_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mmyolo 설치"
      ],
      "metadata": {
        "id": "1YTJDmxdOX3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"Torch version:{}\".format(torch.__version__))\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))"
      ],
      "metadata": {
        "id": "3bP3TCSaKQ0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egIrjmP7Di44"
      },
      "source": [
        "MMYOLO 설치. 현재 mmcv 버전 이슈가 존재하기 때문에 wheel 설치 후 pytorch의 버전을 조절해줘야 한다. 4번 코드블럭이 해당 내용을 포함하고 있음\n",
        "첫 코드블럭 실행하고 재시작 해야됨."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4f1uXQt6fFV"
      },
      "outputs": [],
      "source": [
        "!pip3 install openmim\n",
        "\n",
        "!mim install \"mmengine>=0.6.0\"\n",
        "\n",
        "!pip install wheel\n",
        "!pip install torch==2.0.0 torchvision==0.15.1\n",
        "\n",
        "!mim install \"mmcv>=2.0.0rc4,<2.1.0\"\n",
        "!mim install \"mmdet>=3.0.0,<4.0.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKpp9DnH7E8T"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/open-mmlab/mmyolo.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDhw1n_07Jwx"
      },
      "outputs": [],
      "source": [
        "%cd mmyolo\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwbeOK117m5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06621438-531b-4769-84eb-489118fbbc3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6.0\n"
          ]
        }
      ],
      "source": [
        "import mmyolo\n",
        "print(mmyolo.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터셋 설정"
      ],
      "metadata": {
        "id": "ktu7u8z0LRrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/misc/download_dataset.py --dataset-name cat --save-dir ./data/cat --unzip --delete"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqqSYbkMLXT3",
        "outputId": "43fe9e71-d441-4aa8-e710-af3a07a36e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://download.openmmlab.com/mmyolo/data/cat_dataset.zip to data/cat/cat_dataset.zip\n",
            "100% 217M/217M [00:30<00:00, 7.37MB/s]\n",
            "Unzipping cat_dataset.zip\n",
            "Delete data/cat/cat_dataset.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config 설정"
      ],
      "metadata": {
        "id": "1q5bXqHdLjVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이건 mmyolo 튜토리얼에 존재함.\n",
        "https://github.com/open-mmlab/mmyolo/blob/main/docs/en/get_started/15_minutes_object_detection.md\n"
      ],
      "metadata": {
        "id": "8tJS8QU9MEme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n"
      ],
      "metadata": {
        "id": "1W298gaDMJC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py configs/yolov5/yolov5_s-v61_fast_1xb12-40e_cat.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMX6W5vTLoR9",
        "outputId": "9a8ac372-fb04-485f-a93e-cebe2578ed3e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/18 10:32:14 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmyolo\" in the \"log_processor\" registry tree. As a workaround, the current \"log_processor\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmyolo\" is a correct scope, or whether the registry is initialized.\n",
            "11/18 10:32:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "    CUDA available: False\n",
            "    numpy_random_seed: 1960407591\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.9.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1960407591\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "11/18 10:32:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "_backend_args = None\n",
            "_multiscale_resize_transforms = [\n",
            "    dict(\n",
            "        transforms=[\n",
            "            dict(scale=(\n",
            "                640,\n",
            "                640,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    640,\n",
            "                    640,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "        ],\n",
            "        type='Compose'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            dict(scale=(\n",
            "                320,\n",
            "                320,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    320,\n",
            "                    320,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "        ],\n",
            "        type='Compose'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            dict(scale=(\n",
            "                960,\n",
            "                960,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    960,\n",
            "                    960,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "        ],\n",
            "        type='Compose'),\n",
            "]\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            68,\n",
            "            69,\n",
            "        ),\n",
            "        (\n",
            "            154,\n",
            "            91,\n",
            "        ),\n",
            "        (\n",
            "            143,\n",
            "            162,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            242,\n",
            "            160,\n",
            "        ),\n",
            "        (\n",
            "            189,\n",
            "            287,\n",
            "        ),\n",
            "        (\n",
            "            391,\n",
            "            207,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            353,\n",
            "            337,\n",
            "        ),\n",
            "        (\n",
            "            539,\n",
            "            341,\n",
            "        ),\n",
            "        (\n",
            "            443,\n",
            "            432,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "backend_args = None\n",
            "base_lr = 0.01\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=640,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "class_name = ('cat', )\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = './data/cat/'\n",
            "dataset_type = 'YOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=10, max_keep_ckpts=2, save_best='auto',\n",
            "        type='CheckpointHook'),\n",
            "    logger=dict(interval=5, type='LoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=40,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook',\n",
            "        warmup_mim_iter=10),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'mmyolo'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_scale = (\n",
            "    640,\n",
            "    640,\n",
            ")\n",
            "img_scales = [\n",
            "    (\n",
            "        640,\n",
            "        640,\n",
            "    ),\n",
            "    (\n",
            "        320,\n",
            "        320,\n",
            "    ),\n",
            "    (\n",
            "        960,\n",
            "        960,\n",
            "    ),\n",
            "]\n",
            "launcher = 'none'\n",
            "load_from = 'https://download.openmmlab.com/mmyolo/v0/yolov5/yolov5_s-v61_syncbn_fast_8xb16-300e_coco/yolov5_s-v61_syncbn_fast_8xb16-300e_coco_20220918_084700-86e02187.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr_factor = 0.01\n",
            "max_epochs = 40\n",
            "max_keep_ckpts = 3\n",
            "metainfo = dict(\n",
            "    classes=('cat', ), palette=[\n",
            "        (\n",
            "            20,\n",
            "            220,\n",
            "            60,\n",
            "        ),\n",
            "    ])\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='SiLU'),\n",
            "        deepen_factor=0.33,\n",
            "        frozen_stages=4,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.5),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=1,\n",
            "            type='YOLOv5HeadModule',\n",
            "            widen_factor=0.5),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.5,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=1.0,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        68,\n",
            "                        69,\n",
            "                    ),\n",
            "                    (\n",
            "                        154,\n",
            "                        91,\n",
            "                    ),\n",
            "                    (\n",
            "                        143,\n",
            "                        162,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        242,\n",
            "                        160,\n",
            "                    ),\n",
            "                    (\n",
            "                        189,\n",
            "                        287,\n",
            "                    ),\n",
            "                    (\n",
            "                        391,\n",
            "                        207,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        353,\n",
            "                        337,\n",
            "                    ),\n",
            "                    (\n",
            "                        539,\n",
            "                        341,\n",
            "                    ),\n",
            "                    (\n",
            "                        443,\n",
            "                        432,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='YOLOv5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='YOLOv5DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='SiLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.5),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 1\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=12,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_checkpoint_intervals = 10\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='annotations/test.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=640,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='images/'),\n",
            "        data_root='./data/cat/',\n",
            "        metainfo=dict(classes=('cat', ), palette=[\n",
            "            (\n",
            "                20,\n",
            "                220,\n",
            "                60,\n",
            "            ),\n",
            "        ]),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                640,\n",
            "                640,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    640,\n",
            "                    640,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='YOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file='./data/cat/annotations/test.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        640,\n",
            "        640,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            640,\n",
            "            640,\n",
            "        ),\n",
            "        type='LetterResize'),\n",
            "    dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann_file = 'annotations/instances_train2017.json'\n",
            "train_batch_size_per_gpu = 12\n",
            "train_cfg = dict(max_epochs=40, type='EpochBasedTrainLoop', val_interval=10)\n",
            "train_data_prefix = 'train2017/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=12,\n",
            "    collate_fn=dict(type='yolov5_collate'),\n",
            "    dataset=dict(\n",
            "        ann_file='annotations/trainval.json',\n",
            "        data_prefix=dict(img='images/'),\n",
            "        data_root='./data/cat/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        metainfo=dict(classes=('cat', ), palette=[\n",
            "            (\n",
            "                20,\n",
            "                220,\n",
            "                60,\n",
            "            ),\n",
            "        ]),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                img_scale=(\n",
            "                    640,\n",
            "                    640,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -320,\n",
            "                    -320,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='YOLOv5CocoDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_num_workers = 4\n",
            "train_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        img_scale=(\n",
            "            640,\n",
            "            640,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -320,\n",
            "            -320,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "tta_model = dict(\n",
            "    tta_cfg=dict(max_per_img=300, nms=dict(iou_threshold=0.65, type='nms')),\n",
            "    type='mmdet.DetTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(\n",
            "                    transforms=[\n",
            "                        dict(scale=(\n",
            "                            640,\n",
            "                            640,\n",
            "                        ), type='YOLOv5KeepRatioResize'),\n",
            "                        dict(\n",
            "                            allow_scale_up=False,\n",
            "                            pad_val=dict(img=114),\n",
            "                            scale=(\n",
            "                                640,\n",
            "                                640,\n",
            "                            ),\n",
            "                            type='LetterResize'),\n",
            "                    ],\n",
            "                    type='Compose'),\n",
            "                dict(\n",
            "                    transforms=[\n",
            "                        dict(scale=(\n",
            "                            320,\n",
            "                            320,\n",
            "                        ), type='YOLOv5KeepRatioResize'),\n",
            "                        dict(\n",
            "                            allow_scale_up=False,\n",
            "                            pad_val=dict(img=114),\n",
            "                            scale=(\n",
            "                                320,\n",
            "                                320,\n",
            "                            ),\n",
            "                            type='LetterResize'),\n",
            "                    ],\n",
            "                    type='Compose'),\n",
            "                dict(\n",
            "                    transforms=[\n",
            "                        dict(scale=(\n",
            "                            960,\n",
            "                            960,\n",
            "                        ), type='YOLOv5KeepRatioResize'),\n",
            "                        dict(\n",
            "                            allow_scale_up=False,\n",
            "                            pad_val=dict(img=114),\n",
            "                            scale=(\n",
            "                                960,\n",
            "                                960,\n",
            "                            ),\n",
            "                            type='LetterResize'),\n",
            "                    ],\n",
            "                    type='Compose'),\n",
            "            ],\n",
            "            [\n",
            "                dict(prob=1.0, type='mmdet.RandomFlip'),\n",
            "                dict(prob=0.0, type='mmdet.RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "            ],\n",
            "            [\n",
            "                dict(\n",
            "                    meta_keys=(\n",
            "                        'img_id',\n",
            "                        'img_path',\n",
            "                        'ori_shape',\n",
            "                        'img_shape',\n",
            "                        'scale_factor',\n",
            "                        'pad_param',\n",
            "                        'flip',\n",
            "                        'flip_direction',\n",
            "                    ),\n",
            "                    type='mmdet.PackDetInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_ann_file = 'annotations/instances_val2017.json'\n",
            "val_batch_size_per_gpu = 1\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data_prefix = 'val2017/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='annotations/test.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=640,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='images/'),\n",
            "        data_root='./data/cat/',\n",
            "        metainfo=dict(classes=('cat', ), palette=[\n",
            "            (\n",
            "                20,\n",
            "                220,\n",
            "                60,\n",
            "            ),\n",
            "        ]),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                640,\n",
            "                640,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    640,\n",
            "                    640,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='YOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file='./data/cat/annotations/test.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_num_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='mmdet.DetLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.5\n",
            "work_dir = './work_dirs/yolov5_s-v61_fast_1xb12-40e_cat'\n",
            "\n",
            "!!!You are using `YOLOv5Head` with num_classes == 1. The loss_cls will be 0. This is a normal phenomenon.\n",
            "11/18 10:32:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "11/18 10:32:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "11/18 10:32:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Scaled weight_decay to 0.00046875\n",
            "11/18 10:32:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Optimizer groups: 60 .bias, 60 conv.weight, 57 other\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmyolo/v0/yolov5/yolov5_s-v61_syncbn_fast_8xb16-300e_coco/yolov5_s-v61_syncbn_fast_8xb16-300e_coco_20220918_084700-86e02187.pth\n",
            "Downloading: \"https://download.openmmlab.com/mmyolo/v0/yolov5/yolov5_s-v61_syncbn_fast_8xb16-300e_coco/yolov5_s-v61_syncbn_fast_8xb16-300e_coco_20220918_084700-86e02187.pth\" to /root/.cache/torch/hub/checkpoints/yolov5_s-v61_syncbn_fast_8xb16-300e_coco_20220918_084700-86e02187.pth\n",
            "100% 27.8M/27.8M [00:02<00:00, 9.84MB/s]\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for bbox_head.head_module.convs_pred.0.weight: copying a param with shape torch.Size([255, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([18, 128, 1, 1]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.0.bias: copying a param with shape torch.Size([255]) from checkpoint, the shape in current model is torch.Size([18]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.1.weight: copying a param with shape torch.Size([255, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([18, 256, 1, 1]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.1.bias: copying a param with shape torch.Size([255]) from checkpoint, the shape in current model is torch.Size([18]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.2.weight: copying a param with shape torch.Size([255, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([18, 512, 1, 1]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.2.bias: copying a param with shape torch.Size([255]) from checkpoint, the shape in current model is torch.Size([18]).\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for bbox_head.head_module.convs_pred.0.weight: copying a param with shape torch.Size([255, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([18, 128, 1, 1]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.0.bias: copying a param with shape torch.Size([255]) from checkpoint, the shape in current model is torch.Size([18]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.1.weight: copying a param with shape torch.Size([255, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([18, 256, 1, 1]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.1.bias: copying a param with shape torch.Size([255]) from checkpoint, the shape in current model is torch.Size([18]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.2.weight: copying a param with shape torch.Size([255, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([18, 512, 1, 1]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.2.bias: copying a param with shape torch.Size([255]) from checkpoint, the shape in current model is torch.Size([18]).\n",
            "11/18 10:32:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from https://download.openmmlab.com/mmyolo/v0/yolov5/yolov5_s-v61_syncbn_fast_8xb16-300e_coco/yolov5_s-v61_syncbn_fast_8xb16-300e_coco_20220918_084700-86e02187.pth\n",
            "11/18 10:32:24 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "11/18 10:32:24 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "11/18 10:32:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmyolo/work_dirs/yolov5_s-v61_fast_1xb12-40e_cat.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "11/18 10:34:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 5/10]  base_lr: 1.0000e-02 lr: 1.3333e-03  eta: 2:53:32  time: 26.3595  data_time: 7.1024  loss: 1.7998  loss_cls: 0.0000  loss_obj: 0.4209  loss_bbox: 1.3789\n",
            "11/18 10:35:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: yolov5_s-v61_fast_1xb12-40e_cat_20231118_103214\n",
            "11/18 10:35:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][10/10]  base_lr: 1.0000e-02 lr: 3.0000e-03  eta: 1:55:12  time: 17.7247  data_time: 3.5540  loss: 1.6816  loss_cls: 0.0000  loss_obj: 0.4143  loss_bbox: 1.2673\n",
            "11/18 10:37:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 5/10]  base_lr: 1.0000e-02 lr: 4.5512e-03  eta: 2:14:29  time: 20.9604  data_time: 4.9521  loss: 1.6241  loss_cls: 0.0000  loss_obj: 0.4276  loss_bbox: 1.1965\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/mmyolo/tools/train.py\", line 123, in <module>\n",
            "    main()\n",
            "  File \"/content/mmyolo/tools/train.py\", line 119, in main\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1777, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 96, in run\n",
            "    self.run_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 112, in run_epoch\n",
            "    self.run_iter(idx, data_batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 128, in run_iter\n",
            "    outputs = self.runner.model.train_step(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\", line 116, in train_step\n",
            "    optim_wrapper.update_params(parsed_losses)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/optim/optimizer/optimizer_wrapper.py\", line 196, in update_params\n",
            "    self.backward(loss)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/optim/optimizer/optimizer_wrapper.py\", line 220, in backward\n",
            "    loss.backward(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 487, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 200, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Object Detection"
      ],
      "metadata": {
        "id": "d19hqu4JuTJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과는 work_dirs/yoloV5_s-v61_fast_1xb12-40e_cat/show_results 에 존재한다."
      ],
      "metadata": {
        "id": "otDKlHhf8h_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard"
      ],
      "metadata": {
        "id": "PwXhRJN_uXb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29860798-431c-40b0-9e55-d220c92ffa57"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.14.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.59.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.28.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (60.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/test.py configs/yolov5/yolov5_s-v61_fast_1xb12-40e_cat.py \\\n",
        "                     work_dirs/yolov5_s-v61_fast_1xb12-40e_cat/epoch_40.pth \\\n",
        "                     --show-dir show_results"
      ],
      "metadata": {
        "id": "uotW5zKL6-Xo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4abd2336-7610-4bd8-c6a1-27a44d7af9dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/18 10:38:24 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmyolo\" in the \"log_processor\" registry tree. As a workaround, the current \"log_processor\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmyolo\" is a correct scope, or whether the registry is initialized.\n",
            "11/18 10:38:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "    CUDA available: False\n",
            "    numpy_random_seed: 1926504254\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.9.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1926504254\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "11/18 10:38:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "_backend_args = None\n",
            "_multiscale_resize_transforms = [\n",
            "    dict(\n",
            "        transforms=[\n",
            "            dict(scale=(\n",
            "                640,\n",
            "                640,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    640,\n",
            "                    640,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "        ],\n",
            "        type='Compose'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            dict(scale=(\n",
            "                320,\n",
            "                320,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    320,\n",
            "                    320,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "        ],\n",
            "        type='Compose'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            dict(scale=(\n",
            "                960,\n",
            "                960,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    960,\n",
            "                    960,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "        ],\n",
            "        type='Compose'),\n",
            "]\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            68,\n",
            "            69,\n",
            "        ),\n",
            "        (\n",
            "            154,\n",
            "            91,\n",
            "        ),\n",
            "        (\n",
            "            143,\n",
            "            162,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            242,\n",
            "            160,\n",
            "        ),\n",
            "        (\n",
            "            189,\n",
            "            287,\n",
            "        ),\n",
            "        (\n",
            "            391,\n",
            "            207,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            353,\n",
            "            337,\n",
            "        ),\n",
            "        (\n",
            "            539,\n",
            "            341,\n",
            "        ),\n",
            "        (\n",
            "            443,\n",
            "            432,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "backend_args = None\n",
            "base_lr = 0.01\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=640,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "class_name = ('cat', )\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = './data/cat/'\n",
            "dataset_type = 'YOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=10, max_keep_ckpts=2, save_best='auto',\n",
            "        type='CheckpointHook'),\n",
            "    logger=dict(interval=5, type='LoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=40,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook',\n",
            "        warmup_mim_iter=10),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(\n",
            "        draw=True,\n",
            "        test_out_dir='show_results',\n",
            "        type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'mmyolo'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_scale = (\n",
            "    640,\n",
            "    640,\n",
            ")\n",
            "img_scales = [\n",
            "    (\n",
            "        640,\n",
            "        640,\n",
            "    ),\n",
            "    (\n",
            "        320,\n",
            "        320,\n",
            "    ),\n",
            "    (\n",
            "        960,\n",
            "        960,\n",
            "    ),\n",
            "]\n",
            "launcher = 'none'\n",
            "load_from = 'work_dirs/yolov5_s-v61_fast_1xb12-40e_cat/epoch_40.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr_factor = 0.01\n",
            "max_epochs = 40\n",
            "max_keep_ckpts = 3\n",
            "metainfo = dict(\n",
            "    classes=('cat', ), palette=[\n",
            "        (\n",
            "            20,\n",
            "            220,\n",
            "            60,\n",
            "        ),\n",
            "    ])\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='SiLU'),\n",
            "        deepen_factor=0.33,\n",
            "        frozen_stages=4,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.5),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=1,\n",
            "            type='YOLOv5HeadModule',\n",
            "            widen_factor=0.5),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.5,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=1.0,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        68,\n",
            "                        69,\n",
            "                    ),\n",
            "                    (\n",
            "                        154,\n",
            "                        91,\n",
            "                    ),\n",
            "                    (\n",
            "                        143,\n",
            "                        162,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        242,\n",
            "                        160,\n",
            "                    ),\n",
            "                    (\n",
            "                        189,\n",
            "                        287,\n",
            "                    ),\n",
            "                    (\n",
            "                        391,\n",
            "                        207,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        353,\n",
            "                        337,\n",
            "                    ),\n",
            "                    (\n",
            "                        539,\n",
            "                        341,\n",
            "                    ),\n",
            "                    (\n",
            "                        443,\n",
            "                        432,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='YOLOv5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='YOLOv5DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='SiLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.5),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 1\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=12,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_checkpoint_intervals = 10\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='annotations/test.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=640,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='images/'),\n",
            "        data_root='./data/cat/',\n",
            "        metainfo=dict(classes=('cat', ), palette=[\n",
            "            (\n",
            "                20,\n",
            "                220,\n",
            "                60,\n",
            "            ),\n",
            "        ]),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                640,\n",
            "                640,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    640,\n",
            "                    640,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='YOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file='./data/cat/annotations/test.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        640,\n",
            "        640,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            640,\n",
            "            640,\n",
            "        ),\n",
            "        type='LetterResize'),\n",
            "    dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann_file = 'annotations/instances_train2017.json'\n",
            "train_batch_size_per_gpu = 12\n",
            "train_cfg = dict(max_epochs=40, type='EpochBasedTrainLoop', val_interval=10)\n",
            "train_data_prefix = 'train2017/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=12,\n",
            "    collate_fn=dict(type='yolov5_collate'),\n",
            "    dataset=dict(\n",
            "        ann_file='annotations/trainval.json',\n",
            "        data_prefix=dict(img='images/'),\n",
            "        data_root='./data/cat/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        metainfo=dict(classes=('cat', ), palette=[\n",
            "            (\n",
            "                20,\n",
            "                220,\n",
            "                60,\n",
            "            ),\n",
            "        ]),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                img_scale=(\n",
            "                    640,\n",
            "                    640,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -320,\n",
            "                    -320,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='YOLOv5CocoDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_num_workers = 4\n",
            "train_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        img_scale=(\n",
            "            640,\n",
            "            640,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -320,\n",
            "            -320,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "tta_model = dict(\n",
            "    tta_cfg=dict(max_per_img=300, nms=dict(iou_threshold=0.65, type='nms')),\n",
            "    type='mmdet.DetTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(\n",
            "                    transforms=[\n",
            "                        dict(scale=(\n",
            "                            640,\n",
            "                            640,\n",
            "                        ), type='YOLOv5KeepRatioResize'),\n",
            "                        dict(\n",
            "                            allow_scale_up=False,\n",
            "                            pad_val=dict(img=114),\n",
            "                            scale=(\n",
            "                                640,\n",
            "                                640,\n",
            "                            ),\n",
            "                            type='LetterResize'),\n",
            "                    ],\n",
            "                    type='Compose'),\n",
            "                dict(\n",
            "                    transforms=[\n",
            "                        dict(scale=(\n",
            "                            320,\n",
            "                            320,\n",
            "                        ), type='YOLOv5KeepRatioResize'),\n",
            "                        dict(\n",
            "                            allow_scale_up=False,\n",
            "                            pad_val=dict(img=114),\n",
            "                            scale=(\n",
            "                                320,\n",
            "                                320,\n",
            "                            ),\n",
            "                            type='LetterResize'),\n",
            "                    ],\n",
            "                    type='Compose'),\n",
            "                dict(\n",
            "                    transforms=[\n",
            "                        dict(scale=(\n",
            "                            960,\n",
            "                            960,\n",
            "                        ), type='YOLOv5KeepRatioResize'),\n",
            "                        dict(\n",
            "                            allow_scale_up=False,\n",
            "                            pad_val=dict(img=114),\n",
            "                            scale=(\n",
            "                                960,\n",
            "                                960,\n",
            "                            ),\n",
            "                            type='LetterResize'),\n",
            "                    ],\n",
            "                    type='Compose'),\n",
            "            ],\n",
            "            [\n",
            "                dict(prob=1.0, type='mmdet.RandomFlip'),\n",
            "                dict(prob=0.0, type='mmdet.RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "            ],\n",
            "            [\n",
            "                dict(\n",
            "                    meta_keys=(\n",
            "                        'img_id',\n",
            "                        'img_path',\n",
            "                        'ori_shape',\n",
            "                        'img_shape',\n",
            "                        'scale_factor',\n",
            "                        'pad_param',\n",
            "                        'flip',\n",
            "                        'flip_direction',\n",
            "                    ),\n",
            "                    type='mmdet.PackDetInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_ann_file = 'annotations/instances_val2017.json'\n",
            "val_batch_size_per_gpu = 1\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data_prefix = 'val2017/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='annotations/test.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=640,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='images/'),\n",
            "        data_root='./data/cat/',\n",
            "        metainfo=dict(classes=('cat', ), palette=[\n",
            "            (\n",
            "                20,\n",
            "                220,\n",
            "                60,\n",
            "            ),\n",
            "        ]),\n",
            "        pipeline=[\n",
            "            dict(backend_args=None, type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                640,\n",
            "                640,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    640,\n",
            "                    640,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='YOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file='./data/cat/annotations/test.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_num_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='mmdet.DetLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.5\n",
            "work_dir = './work_dirs/yolov5_s-v61_fast_1xb12-40e_cat'\n",
            "\n",
            "!!!You are using `YOLOv5Head` with num_classes == 1. The loss_cls will be 0. This is a normal phenomenon.\n",
            "11/18 10:38:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "11/18 10:38:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loads checkpoint by local backend from path: work_dirs/yolov5_s-v61_fast_1xb12-40e_cat/epoch_40.pth\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/mmyolo/tools/test.py\", line 158, in <module>\n",
            "    main()\n",
            "  File \"/content/mmyolo/tools/test.py\", line 154, in main\n",
            "    runner.test()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1821, in test\n",
            "    self.load_or_resume()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1699, in load_or_resume\n",
            "    self.load_checkpoint(self._load_from)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 2127, in load_checkpoint\n",
            "    checkpoint = _load_checkpoint(filename, map_location=map_location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/checkpoint.py\", line 548, in _load_checkpoint\n",
            "    return CheckpointLoader.load_checkpoint(filename, map_location, logger)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/checkpoint.py\", line 330, in load_checkpoint\n",
            "    return checkpoint_loader(filename, map_location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/checkpoint.py\", line 346, in load_from_local\n",
            "    raise FileNotFoundError(f'{filename} can not be found.')\n",
            "FileNotFoundError: work_dirs/yolov5_s-v61_fast_1xb12-40e_cat/epoch_40.pth can not be found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zyeU8fsrAzQv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}